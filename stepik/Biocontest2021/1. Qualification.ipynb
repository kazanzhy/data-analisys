{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bioinformatics Contest 2021\n",
    "https://stepik.org/course/91751/syllabus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import resource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epigenomic Marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_states(seq_lst: list):\n",
    "    patterns = {'': 0}\n",
    "    result = []\n",
    "    for state in zip(*seq_lst):\n",
    "        state = ''.join(state)\n",
    "        if state not in patterns:\n",
    "            max_state = max(patterns.values())\n",
    "            patterns[state] = max_state + 1\n",
    "        result.append(patterns.get(state)) \n",
    "    return max(patterns.values()), ' '.join(map(str, result))\n",
    "\n",
    "\n",
    "file = '2'\n",
    "fi = open(f'Epigenomic Marks/{file}.txt')\n",
    "fo = open(f'Epigenomic Marks/{file}_out.txt', 'w')\n",
    "\n",
    "tests_num = int(fi.readline())\n",
    "for t in range(tests_num):\n",
    "    \n",
    "    seq_num, seq_len = map(int, fi.readline().strip().split())\n",
    "    test_seqs = []\n",
    "    for n in range(seq_num):\n",
    "        test_seqs.append(fi.readline().strip())\n",
    "    max_state, states = get_states(test_seqs)\n",
    "    fo.write(f'{max_state}\\n{states}\\n')\n",
    "\n",
    "fi.close()\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metabolite Annotation\n",
    "https://www.geeksforgeeks.org/given-two-sorted-arrays-number-x-find-pair-whose-sum-closest-x/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive realisation (good for 0, 1, 2)\n",
    "file = '0'\n",
    "fi = open(f'Metabolite Annotation/{file}.txt')\n",
    "fo = open(f'Metabolite Annotation/{file}_out.txt', 'w')\n",
    "\n",
    "tests_num = int(fi.readline())\n",
    "for t in range(tests_num):\n",
    "    M, K, N = map(int, fi.readline().strip().split())\n",
    "    metabos = list(map(float, fi.readline().strip().split()))\n",
    "    metabos = np.array(metabos).reshape(M,1)\n",
    "    adducts = list(map(float, fi.readline().strip().split()))\n",
    "    adducts = np.array(adducts).reshape(1,K)\n",
    "    matrix = np.zeros((M, K)) + metabos + adducts\n",
    "    del metabos, adducts\n",
    "    for sam in map(float, fi.readline().strip().split()):\n",
    "        ind = np.unravel_index(np.argmin(np.absolute(matrix - sam)), (M, K))\n",
    "        fo.write(f'{ind[0] + 1} {ind[1] + 1}\\n')\n",
    "\n",
    "fi.close()\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for 3, 4, 5\n",
    "file = '5'\n",
    "fi = open(f'Metabolite Annotation/{file}.txt')\n",
    "fo = open(f'Metabolite Annotation/{file}_out.txt', 'w')\n",
    "\n",
    "def searchClosest(sample):\n",
    "    global metabos, adducts, M, K\n",
    "    diff = float('inf') \n",
    "    l = 0\n",
    "    r = K - 1\n",
    "    while(l < M and r >= 0):\n",
    "        if abs(metabos[l][0] + adducts[r][0] - sample) < diff:\n",
    "            res_l = l\n",
    "            res_r = r\n",
    "            diff = abs(metabos[l][0] + adducts[r][0] - sample)\n",
    "        if metabos[l][0] + adducts[r][0] > sample:\n",
    "            r -= 1\n",
    "        else:\n",
    "            l += 1\n",
    "    return (metabos[res_l][1], adducts[res_r][1])\n",
    "\n",
    "\n",
    "tests_num = int(fi.readline())\n",
    "for t in range(tests_num):\n",
    "    M, K, N = map(int, fi.readline().strip().split())\n",
    "    \n",
    "    metabos = np.array(fi.readline().strip().split(), dtype=np.float)\n",
    "    metabos = np.vstack([metabos, range(M)]).transpose()\n",
    "    metabos = metabos[metabos[:,0].argsort()]\n",
    "    \n",
    "    adducts = np.array(fi.readline().strip().split(), dtype=np.float)\n",
    "    adducts = np.vstack([adducts, range(K)]).transpose()\n",
    "    adducts = adducts[adducts[:,0].argsort()]\n",
    "    \n",
    "    samples = np.array(fi.readline().strip().split(), dtype=np.float)\n",
    "    for sam in samples:\n",
    "        ind = searchClosest(sam)\n",
    "        m, a = map(lambda x: int(x) + 1, ind)\n",
    "        fo.write(f'{m} {a}\\n')\n",
    "\n",
    "fi.close()\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnosis\n",
    "https://e-maxx.ru/algo/lca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices: 19830\n",
      "Diseases: 5000\n",
      "Patients: 5000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import resource\n",
    "\n",
    "# Load data\n",
    "file = '1'\n",
    "fi = open(f'Diagnosis/test{file}')\n",
    "\n",
    "hpo_vertices_num = int(fi.readline())\n",
    "print('Vertices:', hpo_vertices_num)\n",
    "hpo_parents = np.array(fi.readline().strip().split(), int) - 1\n",
    "hpo_values = np.array(fi.readline().strip().split(), int)\n",
    "\n",
    "diseases_num = int(fi.readline())\n",
    "print('Diseases:', diseases_num)\n",
    "diseases = []\n",
    "for _ in range(diseases_num):\n",
    "    diseases.append(np.array(fi.readline().strip().split()[1:], int) - 1)\n",
    "    \n",
    "patients_num = int(fi.readline())\n",
    "print('Patients:', patients_num)\n",
    "patients = []\n",
    "for _ in range(patients_num):\n",
    "    patients.append(np.array(fi.readline().strip().split()[1:], int) - 1)\n",
    "fi.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make preprocessing\n",
    "# Deep reccursion is needed, but it can cause StackOverflow. That's why stack should be enlarged\n",
    "sys.setrecursionlimit(max(sys.getrecursionlimit(), hpo_vertices_num))\n",
    "resource.setrlimit(resource.RLIMIT_STACK, (resource.RLIM_INFINITY, resource.RLIM_INFINITY))\n",
    "\n",
    "# create array with list of children of vertex\n",
    "hpo_children = [[] for i in range(hpo_vertices_num)]\n",
    "for child, par in enumerate(hpo_parents, 1):\n",
    "    hpo_children[par].append(child)\n",
    "hpo_children = [np.array(lst, int) for lst in hpo_children]\n",
    "\n",
    "# Run Deep first search over the tree\n",
    "hpo_order = []\n",
    "hpo_first = np.zeros((hpo_vertices_num), int)\n",
    "hpo_depth = np.zeros((hpo_vertices_num), int)\n",
    "def dfs(vert, depth):\n",
    "    global hpo_depth, hpo_order, hpo_first\n",
    "    hpo_depth[vert] = depth\n",
    "    hpo_order.append(vert)\n",
    "    hpo_first[vert] = len(hpo_order) - 1\n",
    "    for c in hpo_children[vert]:\n",
    "        dfs(c, depth + 1)\n",
    "        hpo_order.append(vert)\n",
    "dfs(0, 0)\n",
    "hpo_order = np.array(hpo_order, int)\n",
    "\n",
    "# Create segment_tree on order\n",
    "hpo_segment_tree = np.zeros((hpo_order.size * 4 + 1), int)\n",
    "def build_segment_tree(i, l, r):\n",
    "    global hpo_segment_tree\n",
    "    if l == r:\n",
    "        hpo_segment_tree[i] = hpo_order[l]\n",
    "    else:\n",
    "        m = (l + r) // 2\n",
    "        build_segment_tree(i+i, l, m)\n",
    "        build_segment_tree(i+i+1, m+1, r)\n",
    "        if hpo_depth[hpo_segment_tree[i+i]] < hpo_depth[hpo_segment_tree[i+i+1]]:\n",
    "            hpo_segment_tree[i] = hpo_segment_tree[i+i]\n",
    "        else:\n",
    "            hpo_segment_tree[i] = hpo_segment_tree[i+i+1]\n",
    "build_segment_tree(1, 0, hpo_order.size - 1)\n",
    "\n",
    "def bs_segment_tree(i, sl, sr, l, r):\n",
    "    if (sl == l and sr == r):\n",
    "        return hpo_segment_tree[i]\n",
    "    sm = (sl + sr) // 2\n",
    "    if r <= sm:\n",
    "        return bs_segment_tree(i+i, sl, sm, l, r)\n",
    "    if l > sm:\n",
    "        return bs_segment_tree (i+i+1, sm+1, sr, l, r)\n",
    "    ans1 = bs_segment_tree(i+i, sl, sm, l, sm)\n",
    "    ans2 = bs_segment_tree(i+i+1, sm+1, sr, sm+1, r)\n",
    "    if hpo_depth[ans1] < hpo_depth[ans2]:\n",
    "        return ans1\n",
    "    else:\n",
    "        return ans2\n",
    "\n",
    "# Calculate LCA\n",
    "def lca(a, b):\n",
    "    left, right = hpo_first[a], hpo_first[b]\n",
    "    if (left > right):\n",
    "        left, right = right, left\n",
    "    return bs_segment_tree(1, 0, hpo_order.size-1, left, right);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 5000\r"
     ]
    }
   ],
   "source": [
    "# Calculate results\n",
    "def calculate_score(patient, disease):\n",
    "    symtoms_sum = 0\n",
    "    for sym in patient:\n",
    "        max_sign_val = 0\n",
    "        for sign in disease:\n",
    "            lca_val = hpo_values[lca(sym, sign)]\n",
    "            if lca_val > max_sign_val:\n",
    "                max_sign_val = lca_val\n",
    "        symtoms_sum += max_sign_val\n",
    "    return symtoms_sum\n",
    "        \n",
    "fo = open(f'Diagnosis/test{file}_out', 'w')\n",
    "for pi, patient in enumerate(patients):\n",
    "    max_dis_idx, max_dis_val = None, 0\n",
    "    for di, disease in enumerate(diseases):\n",
    "        score = calculate_score(patient, disease)\n",
    "        if score > max_dis_val:\n",
    "            max_dis_idx, max_dis_val = di, score\n",
    "    fo.write(f'{max_dis_idx + 1}\\n')\n",
    "    print(pi+1, patients_num, end='\\r')\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
